# ==============================

# APP

# ==============================

PORT=Your_PORT_HERE
ENV=Your_Env_Here
LOG_LEVEL=Your_Log_Level_Here

# ==============================

# GITHUB APP

# ==============================

GITHUB_APP_ID=Your_GITHUB_APP_ID_HERE
GITHUB_INSTALLATION_ID=Your_GITHUB_INSTALLATION_ID_HERE
GITHUB_PRIVATE_KEY_PATH=./keys/github.pem
GITHUB_WEBHOOK_SECRET=Your_GITHUB_WEBHOOK_SECRET_HERE

# ==============================

# AI PROVIDER

# ==============================

## OpenAI

OPENAI_API_KEY=Your_OPENAI_API_KEY_HERE
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.2
OPENAI_MAX_TOKENS=2000

## Ollama (local alternative)

OLLAMA_HOST=[http://localhost:11434](http://localhost:11434)
OLLAMA_MODEL=llama3

# Choose provider: openai | ollama

AI_PROVIDER=openai

# ==============================

# DATABASE

# ==============================

DB_HOST=Your_DB_Host_Here
DB_PORT=Your_DB_PORT_Here
DB_USER=Your_DB_USER_HERE
DB_PASSWORD=Your_DB_PASSWORD_HERE
DB_NAME=Your_DB_NAME_HERE
DB_SSLMODE=disable

# ==============================

# REDIS / QUEUE

# ==============================
QUEUE_TYPE=Your_QUEUE_TYPE_HERE # memory | redis
REDIS_ADDR=Your_REDIS_ADDR_HERE
REDIS_PASSWORD=Your_REDIS_PASSWORD_HERE
REDIS_DB=0

# ==============================

# OBSERVABILITY

# ==============================

METRICS_PORT=Your_METRICS_PORT_HERE
TRACING_ENABLED=false

# ==============================

# LIMITS

# ==============================

MAX_FILES_PER_PR=20
MAX_TOKENS_PER_FILE=6000
REQUEST_TIMEOUT_SECONDS=60
RETRY_COUNT=3
